{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import gc\n",
    "import utils as u\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import f1_score, confusion_matrix, matthews_corrcoef, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from plotnine import (element_blank, scale_color_manual, scale_x_continuous, ggplot, aes, geom_line ,geom_bar, geom_point, theme, element_text, labs, ggtitle, scale_y_continuous, coord_flip, ggsave)\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defin path and load train and test data \n",
    "final_data_path = 'final data/'\n",
    "tr = pd.read_csv(final_data_path + 'train_data_final.csv', index_col = 0)\n",
    "te = pd.read_csv(final_data_path + 'test_data_final.csv', index_col = 0)\n",
    "te_dm = xgb.DMatrix(te.drop(['Id'], axis = 1))\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1183747, 21)\n",
      "(1183748, 21)\n"
     ]
    }
   ],
   "source": [
    "# train_x, train_y \n",
    "x = tr.drop(['Id', 'Response'], axis = 1)\n",
    "y = tr['Response']\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hp_train_model(x: pd.DataFrame, y: pd.DataFrame, n_tree:int, early_stopping_rounds:int, params = None, te = te):\n",
    "    \n",
    "    mcc_scores = []\n",
    "    evals_result = {}\n",
    "\n",
    "    tr_x, va_x, tr_y, va_y = train_test_split(x, y, test_size = 0.2, random_state = 70, shuffle = True)\n",
    "    dtrain = xgb.DMatrix(tr_x, label = tr_y)\n",
    "    dvalid = xgb.DMatrix(va_x, label = va_y)\n",
    "    watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "\n",
    "    model = xgb.train(params = params, \n",
    "                      dtrain = dtrain, \n",
    "                      num_boost_round = n_tree, \n",
    "                      evals = watchlist, \n",
    "                      verbose_eval=1, \n",
    "                      early_stopping_rounds=early_stopping_rounds, \n",
    "                      evals_result=evals_result,\n",
    "                      feval = u.evalerror\n",
    "                      )\n",
    "        \n",
    "    va_pred = model.predict(dvalid)\n",
    "    _, mcc_value= u.best_thr_mcc(va_pred, dvalid)\n",
    "    mcc_scores.append(mcc_value)\n",
    "\n",
    "    history.append((params, mcc_value))\n",
    "\n",
    "    print('mcc value: {}'.format(round(mcc_value, 3)))\n",
    "    gc.collect()\n",
    "\n",
    "    return np.mean(mcc_scores)\n",
    "\n",
    "def hp_xgb_model(params):\n",
    "    \n",
    "    n_tree = int(params['n_tree'])\n",
    "    early_stopping_rounds = int(round(3/ (1/params['eta']), 0))\n",
    "\n",
    "    xgb_params = {'colsample_bytree': params['colsample_bytree'], \n",
    "                  'eta': 1/params['eta'],\n",
    "                  'max_depth': int(params['max_depth']),\n",
    "                  'subsample': params['subsample'],\n",
    "                  'min_child_weight': int(params['min_child_weight']), \n",
    "                  'gamma': params['gamma']/ 10,\n",
    "                #   'alpha': params['alpha'],\n",
    "                  'objective': 'binary:logistic',\n",
    "                  'random_state': 123,\n",
    "                  'disable_default_eval_metric': 1,\n",
    "                  'ntree': n_tree, \n",
    "                  'early_stopping_rounds': early_stopping_rounds\n",
    "                  }\n",
    "                        \n",
    "    score = train_model(x = x, y = y, n_tree = n_tree, \n",
    "                        early_stopping_rounds = early_stopping_rounds, \n",
    "                        params = xgb_params)\n",
    "    return {'loss':-score, 'status': STATUS_OK }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "         'n_tree'   : hp.quniform('n_tree', 30, 100, 10),\n",
    "         'min_child_weight': hp.quniform('min_child_weight', 1, 8, 1),\n",
    "         'max_depth': hp.quniform('max_depth', 3, 12, 2),\n",
    "         'subsample': hp.quniform('subsample', 0.6, 0.95, 0.05),\n",
    "         'colsample_bytree': hp.quniform('colsample_bytree', 0.6, 0.95, 0.05),\n",
    "         'eta'      : hp.uniform('eta', 10, 100),\n",
    "         'gamma'    : hp.randint('gamma', 2),\n",
    "        #  'alpha'    : hp.loguniform('alpha', np.log(1e-5), np.log(1e2))\n",
    "        }\n",
    "\n",
    "history = []\n",
    "trials = Trials()\n",
    "best = fmin(fn = hp_xgb_model, space = space, algo = tpe.suggest, max_evals = 70, trials = trials)\n",
    "print('='*20)\n",
    "# print(sorted(history, key = lambda tpl: tpl[1])[0][0])\n",
    "# print(sorted(history, key = lambda tpl: tpl[1])[0][1])\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x: pd.DataFrame, y: pd.DataFrame, n_fold: int, n_tree:int, early_stopping_rounds:int, params = None, te = te):\n",
    "    \n",
    "    kf = StratifiedKFold(n_splits = n_fold, shuffle = True, random_state = 123)\n",
    "\n",
    "    scores = {'fold':[], 'mcc':[], 'g_means':[], 'auc_scores':[], 'f1_scores':[], 'threshold':[]}\n",
    "\n",
    "    evals_result = {}\n",
    "    loss_data = pd.DataFrame()\n",
    "    #roc_data  = pd.DataFrame()\n",
    "    predictions = np.zeros(len(te))\n",
    "\n",
    "    for fold_i, (tr_idx, va_idx) in enumerate(kf.split(x, y)):\n",
    "    \n",
    "        temp_loss_data = pd.DataFrame()\n",
    "        #temp_roc_data  = pd.DataFrame()\n",
    "\n",
    "        tr_x, va_x = x.iloc[tr_idx], x.iloc[va_idx]\n",
    "        tr_y, va_y = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "\n",
    "        dtrain = xgb.DMatrix(tr_x, label = tr_y)\n",
    "        dvalid = xgb.DMatrix(va_x, label = va_y)\n",
    "        watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "\n",
    "        model = xgb.train(params = params, \n",
    "                          dtrain = dtrain, \n",
    "                          num_boost_round = n_tree, \n",
    "                          evals = watchlist, \n",
    "                          verbose_eval=1, \n",
    "                          early_stopping_rounds=early_stopping_rounds, \n",
    "                          evals_result=evals_result,\n",
    "                          feval = u.evalerror\n",
    "                         )\n",
    "        \n",
    "        va_pred = model.predict(dvalid)\n",
    "\n",
    "        #temp_roc_data = pd.DataFrame({'va_test':va_y, 'va_pred':va_pred})\n",
    "\n",
    "        prediction = model.predict(xgb.DMatrix(te.drop(['Id'], axis = 1)))\n",
    "        predictions += prediction\n",
    "        \n",
    "        if (fold_i + 1) == n_fold:\n",
    "            predictions /= (fold_i + 1)\n",
    "\n",
    "        best_thresh, mcc_value= u.best_thr_mcc(va_pred, dvalid)\n",
    "        y_pred = np.array([1 if y_pro > best_thresh else 0 for y_pro in va_pred])\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(va_y, y_pred).ravel()\n",
    "        spec = tn / (tn + fp)\n",
    "        sens = tp / (tp + fn)\n",
    "        g_means = np.sqrt(spec * sens)\n",
    "        fmeasure = f1_score(va_y, y_pred)\n",
    "        auc_score = roc_auc_score(va_y, y_pred)\n",
    "\n",
    "        temp_loss_data = pd.DataFrame({'train': list(evals_result['train'].values())[0],\n",
    "                                    'test': list(evals_result['eval'].values())[0],\n",
    "                                    'tree': [i+1 for i in range(len(list(evals_result['train'].values())[0]))]})\n",
    "\n",
    "        print('mcc value: {}'.format(round(mcc_value, 3)))\n",
    "        print('g_means value: {}'.format(round(g_means, 3)))\n",
    "        print('auc value: {}'.format(round(auc_score, 3)))\n",
    "        print('f1_score value: {}'.format(round(fmeasure, 3)))\n",
    "        print('threshold: {}'.format(round(best_thresh, 3)))\n",
    "        \n",
    "        loss_data = pd.concat([loss_data, temp_loss_data], axis = 0).reset_index(drop=True)\n",
    "        scores['fold'].append(fold_i + 1)\n",
    "        scores['mcc'].append(mcc_value)\n",
    "        scores['g_means'].append(g_means)\n",
    "        scores['f1_scores'].append(fmeasure)\n",
    "        scores['auc_scores'].append(auc_score)\n",
    "        scores['threshold'].append(best_thresh)\n",
    "        \n",
    "        gc.collect()\n",
    "    \n",
    "    return model, scores, loss_data, predictions, np.mean(scores['mcc'])\n",
    "\n",
    "def xgb_model(params):\n",
    "    \n",
    "    n_fold = 5\n",
    "    n_tree = int(params['n_tree'])\n",
    "    early_stopping_rounds = int(round(5/ (1/params['eta']), 0))\n",
    "\n",
    "    xgb_params = {'colsample_bytree': params['colsample_bytree'], \n",
    "                  'eta': 1/params['eta'],\n",
    "                  'max_depth': int(params['max_depth']),\n",
    "                  'subsample': params['subsample'],\n",
    "                  'min_child_weight': int(params['min_child_weight']), \n",
    "                  'gamma': params['gamma']/ 10,\n",
    "                  'ntree': n_tree, \n",
    "                  'early_stopping_rounds': early_stopping_rounds,\n",
    "                  'objective': 'binary:logistic',\n",
    "                  'random_state': 123,\n",
    "                  'disable_default_eval_metric': 1\n",
    "                  }\n",
    "                        \n",
    "    model, scores, loss_data, predictions, mcc = train_model(x = x, y = y, n_fold = n_fold, n_tree = n_tree, \n",
    "                                                             early_stopping_rounds = early_stopping_rounds, \n",
    "                                                             params = xgb_params)\n",
    "    return model, scores, loss_data, predictions, mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, scores, loss_data, predictions, mcc = xgb_model(best)\n",
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = xgb.Booster()\n",
    "# model.load_model(path + \"xgboost_model.json\")\n",
    "fscore = model.get_score(importance_type = 'gain')\n",
    "\n",
    "keys = list(fscore.keys())\n",
    "values = list(fscore.values())\n",
    "feat_imp = pd.DataFrame({'feature': keys, 'scores': values}, index=keys).sort_values(by = \"scores\", ascending=True)\n",
    "feat_imp['feature'] = pd.Categorical(\n",
    "feat_imp.feature, categories=pd.unique(feat_imp.feature))\n",
    "feat_imp['score'] = feat_imp['scores'].transform(lambda x: (x/float(x.sum())*100))\n",
    "\n",
    "g = (\n",
    "    ggplot(feat_imp.iloc[-10:, :])\n",
    "    + geom_bar(aes(x = 'feature', y = 'score'), stat = \"identity\", color='#7cc8e9', fill='#7cc8e9', width = 0.5)\n",
    "    + theme(axis_text_x = element_text(angle = 0, size = 13),\n",
    "            axis_text_y=element_text(size=13),\n",
    "            plot_title=element_text(size=18))\n",
    "    + scale_y_continuous(breaks = range(0, 100, 5))\n",
    "    + coord_flip()\n",
    "    + labs(x = 'features',y = 'importance percentages (%)')\n",
    "    + ggtitle('Features importance of categorical data')\n",
    ")\n",
    "# ggsave(file=\"Features importance of numeric data.svg\", plot = g, width = 10, height = 8, dpi = 500, format = 'svg')\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_data[['train', 'test']] = loss_data[['train', 'test']] * -1\n",
    "loss_data = loss_data.groupby('tree')['train', 'test'].mean().reset_index()\n",
    "loss_data = pd.melt(loss_data, id_vars = ['tree'], value_vars = ['train', 'test'])\n",
    "loss_data['variable'] = loss_data['variable'].astype('category')\n",
    "\n",
    "g = (ggplot(loss_data, aes(x = 'tree', y = 'value', group = 'variable', color = 'variable', linetype = 'variable')) \n",
    "     + geom_line(size = 1.5)\n",
    "    #  + geom_smooth(method = 'lm') \n",
    "     + theme(axis_text_x = element_text(size = 13),\n",
    "             axis_text_y = element_text(size = 13),\n",
    "             axis_title = element_text(size = 14),\n",
    "             legend_text = element_text(size = 14),\n",
    "             legend_title = element_blank())\n",
    "     + scale_x_continuous(breaks = range(1, 76, 5))\n",
    "     + scale_y_continuous(breaks = np.linspace(0, 1.0, 21, endpoint = True))\n",
    "     + scale_color_manual(values=[\"#619ED6\", \"#6BA547\"])\n",
    "     + labs(x = 'number of rounds', y = 'MCC')\n",
    "     + ggtitle('XGBoost MCC vs number of rounds')\n",
    "    )\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'model/2.xgboost/'\n",
    "pd.DataFrame({'parameters': best}).to_csv(path + 'best_parameters.csv', index = True)\n",
    "# best = pd.read_csv(path + 'best_parameters.csv', index_col = 0).to_dict\n",
    "\n",
    "pd.DataFrame(scores).to_csv(path + 'xgboost_scores.csv', index = False)\n",
    "loss_data.to_csv(path + 'xgboost_loss_data.csv', index = False)\n",
    "model.save_model(path + \"xgboost_model.json\")\n",
    "\n",
    "# private: 0.46694\n",
    "submission = pd.DataFrame({'Id': te['Id'], 'Response': predictions > np.mean(scores['threshold'])})\n",
    "submission['Response'] = submission['Response'].astype('int')\n",
    "submission.to_csv(path + 'submission_xgboost.csv', index = 0)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7ab622567d5dd62d8f3cbe4f9041d16392fede1d1b7e8653be16112644bf1804"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('tutorial-venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
